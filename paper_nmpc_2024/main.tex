\documentclass{ifacconf}

\usepackage{graphicx}      % include this line if your document contains figures
\usepackage{natbib}        % required for bibliography

\usepackage{xcolor}        % for colored text
%===============================================================================
\begin{document}
\begin{frontmatter}

   \title{RLMPC: A Python Module for Reinforcement Learning based on Model Predictive Control}

   \thanks[footnoteinfo]{
      This research was funded by the Research Council of Norway
      (RCN) through the project Safe Reinforcement Learning using MPC
      (SARLEM), grant number 300172. (e-mail: \{dirk.p.reinhardt, shambhuraj.sawant, wenqi.cai, akhil.s.anand, sebastien.gros\}@ntnu.no).
   }

   \author[First]{Dirk Reinhardt}
   \author[First]{Shambhuraj Sawant}
   \author[First]{Wenqi Cai}
   \author[First]{Akhil S. Anand}
   \author[First]{Sebastien Gros}

   \address[First]{Department of Engineering Cybernetics, Norwegian University of Science and Technology, Trondheim, Norway}

   \begin{abstract}  % Abstract of 50--100 words
      Implement a Python module for reinforcement learning based on model predictive control (RLMPC). The module is
      based built around popular reinforcement learning libraries such as OpenAI Gym and Stable Baselines. It
      provides a set of tools to train and evaluate reinforcement learning agents in a model predictive control
      setting. The module is designed to be modular and extensible. It is easy to use and can be used to tune
      model predictive control algorithms for a wide range of control problems. The module is open-source and
      available on GitHub.
   \end{abstract}

   \begin{keyword}
      % https://ifac.papercept.net/conferences/conferences/IFAC23/program/IFAC23_KeywordIndexWeb.html
      Model predictive and optimization-based control; Reinforcement learning and deep learning in control; Learning for control; Machine learninng; Machine learning in modelling, prediction, control and automation
   \end{keyword}

\end{frontmatter}

% Submission to https://nmpc2024.org/
%===============================================================================

\section{Introduction}

\subsection{Motivation and Background}

\textcolor{red}{
   \begin{itemize}
      \item Discuss the importance of model predictive control (MPC) in industry and academia. Discuss economic model predictive control (EMPC). Reinforcement Learning (RL), and the combination of both. Point to theoretical papers, e.g. \cite{Gros2020}.
      \item Open-source software is important for reproducibility and to accelerate research. We want to provide a tool for the community to tune MPC algorithms using RL / to use structured function approximators in RL.
      \item Share experience and practical considerations from our research when implementing RLMPC algorithms. Point to practical papers, e.g. \citep{Wenqi2021CDCgrid,Wenqi2021CDCShip}.
   \end{itemize}
}


\subsection{Learning-based MPC schemes}

Predictive Control schemes that use Machine Learning tools in the formulation of the Optimal Control Problem

\textcolor{red}{
   \begin{itemize}
      \item GP-MPC~\citep{Berkenkamp2016}
      \item Bayesian Optimization~\cite{Hewing2020a}
      \item Gpflow \citep{GPflow2017}
   \end{itemize}
}

\subsection{MPC-based Learning schemes}

Learning schemes that use MPC as a policy, function approximator, etc.

\cite{Berkenkamp2017}

\subsection{Dependencies}
\begin{itemize}
   \item Gymnasium~\citep{towers_gymnasium_2023}
   \item Stable-Baselines3~\citep{raffin2021reliable}
   \item CasADi~\citep{Andersson2019}
   \item acados~\citep{Verschueren2022}
   \item Ipopt~\citep{Waechter2006}
\end{itemize}

\textcolor{red}{
   \begin{itemize}
      \item Other repositories that combine MPC and any form of learning.
   \end{itemize}
}

\subsection{Outline and Contributions}

\textcolor{red}{
   \begin{itemize}
      \item Contribution is a Python module for RLMPC for everyone to use and to contribute to.
      \item Outline of the paper.
   \end{itemize}
}

\section{Reinforcement Learning based on Model Predictive Control in a Nutshell}

\textcolor{red}{
   \begin{itemize}
      \item Discuss the basics or RL, MPC, and how they connect via the Bellman equations / Markov decision process. We did that a few times already, so we can be brief.
   \end{itemize}
}

\section{The RLMPC Module}

\textcolor{red}{
   \begin{itemize}
      \item Central contriution of the paper: The RLMPC module.
      \item Discuss the design of the module, the main components, and how they interact.
      \item Guideline for how to use the module.
   \end{itemize}
}

\section{Case Studies}

\textcolor{red}{
   \begin{itemize}
      \item Discuss the case studies that we have implemented using the RLMPC module: Data-driven smarthome simulator and the inverted pendulum on a cart problem.
      \item Discuss the results.
   \end{itemize}
}

\section{Practical Considerations}

\textcolor{red}{
   \begin{itemize}
      \item Discuss practical considerations when implementing RLMPC algorithms.
      \item Discuss the challenges that we faced, i.e. hyperparameter tuning, etc. Give some guidelines.
   \end{itemize}
}

\section{Conclusion}

\begin{ack}
   Place acknowledgments here.
\end{ack}

\bibliography{references}

\end{document}
